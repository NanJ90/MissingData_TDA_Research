{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Takens' Embedding Framework - Demo with Imputed Datasets\n",
        "\n",
        "This notebook demonstrates how to use the reusable Takens' Embedding Framework to analyze:\n",
        "- Original datasets\n",
        "- Imputed datasets (with 10-30% missing values)\n",
        "- Multiple imputation methods (KNN, Interpolation, LOCF, GAN)\n",
        "- Multiple missing patterns (MCAR, MAR, MNAR)\n",
        "\n",
        "## Framework Features:\n",
        "- **Dataset-agnostic**: Works with any time series dataset\n",
        "- **Easy integration**: Simple API for loading and comparing datasets\n",
        "- **Imputation support**: Built-in support for imputed datasets\n",
        "- **Comparison tools**: Compare original vs imputed point clouds\n",
        "- **Visualization**: Automatic plotting and analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the framework\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
        "\n",
        "from takens_framework import TakensEmbeddingFramework\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import glob\n",
        "\n",
        "print(\"✓ Framework imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Initialize the Framework\n",
        "\n",
        "Configure the embedding parameters:\n",
        "- **dimension**: Embedding dimension (default: 3 for 3D visualization)\n",
        "- **time_delay**: Time delay parameter τ (default: 1)\n",
        "- **normalize**: Whether to normalize data (recommended: True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize framework with custom parameters\n",
        "framework = TakensEmbeddingFramework(\n",
        "    dimension=3,        # 3D embedding for visualization\n",
        "    time_delay=1,       # Time delay parameter\n",
        "    stride=1,           # Sample every point\n",
        "    normalize=True,     # Normalize data\n",
        "    random_state=42     # For reproducibility\n",
        ")\n",
        "\n",
        "print(\"✓ Framework initialized\")\n",
        "print(f\"  - Embedding dimension: {framework.dimension}\")\n",
        "print(f\"  - Time delay: {framework.time_delay}\")\n",
        "print(f\"  - Normalization: {framework.normalize}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Original and Imputed Datasets\n",
        "\n",
        "The framework can automatically load:\n",
        "- Original complete dataset\n",
        "- All imputed datasets from a pickle file\n",
        "- Handles multiple imputation methods and missing patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find imputed datasets\n",
        "imp_data_dir = 'imp_data'\n",
        "if os.path.exists(imp_data_dir):\n",
        "    pickle_files = glob.glob(f'{imp_data_dir}/imputed_datasets_*.pkl')\n",
        "    if pickle_files:\n",
        "        # Use the most recent file\n",
        "        imputed_data_path = sorted(pickle_files)[-1]\n",
        "        print(f\"Found imputed datasets: {imputed_data_path}\")\n",
        "    else:\n",
        "        print(\"No imputed datasets found. Please run imputation.py first.\")\n",
        "        imputed_data_path = None\n",
        "else:\n",
        "    print(\"imp_data directory not found. Please run imputation.py first.\")\n",
        "    imputed_data_path = None\n",
        "\n",
        "# Load original dataset\n",
        "original_data_path = 'data/eeg_eye_state_full.csv'\n",
        "if os.path.exists(original_data_path):\n",
        "    print(f\"Found original dataset: {original_data_path}\")\n",
        "else:\n",
        "    print(\"Original dataset not found. Will try to load from UCI repository.\")\n",
        "    original_data_path = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets using the framework\n",
        "if imputed_data_path and original_data_path:\n",
        "    # Load imputed datasets with original\n",
        "    framework.load_imputed_datasets(\n",
        "        imputed_data_path=imputed_data_path,\n",
        "        original_data=original_data_path,\n",
        "        original_name='original',\n",
        "        target_column='target'  # For grouping by eye state\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n✓ Loaded {len(framework.datasets)} datasets\")\n",
        "    print(f\"  Available datasets: {list(framework.datasets.keys())[:5]}...\")  # Show first 5\n",
        "elif original_data_path:\n",
        "    # Load only original if imputed not available\n",
        "    framework.load_dataset(\n",
        "        original_data_path,\n",
        "        name='original',\n",
        "        target_column='target'\n",
        "    )\n",
        "    print(f\"\\n✓ Loaded original dataset\")\n",
        "else:\n",
        "    print(\"⚠ No datasets found. Please ensure data files exist.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Point Clouds for Comparison\n",
        "\n",
        "Compare point clouds across:\n",
        "- Original vs Imputed datasets\n",
        "- Different imputation methods (KNN, Interpolation, LOCF, GAN)\n",
        "- Different missing patterns (MCAR, MAR, MNAR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select datasets to compare\n",
        "# You can customize this list based on available datasets\n",
        "datasets_to_compare = ['original']\n",
        "\n",
        "# Add imputed datasets if available\n",
        "if len(framework.datasets) > 1:\n",
        "    # Example: Compare original with KNN imputed for MCAR pattern\n",
        "    for name in framework.datasets.keys():\n",
        "        if 'knn' in name.lower() and 'mcar' in name.lower():\n",
        "            datasets_to_compare.append(name)\n",
        "            break\n",
        "        if 'gan' in name.lower() and 'mcar' in name.lower():\n",
        "            datasets_to_compare.append(name)\n",
        "            break\n",
        "\n",
        "print(f\"Comparing datasets: {datasets_to_compare}\")\n",
        "\n",
        "# Create point clouds for comparison\n",
        "channel_idx = 0  # First EEG channel\n",
        "comparison_results = framework.compare_datasets(\n",
        "    dataset_names=datasets_to_compare,\n",
        "    channel_idx=channel_idx,\n",
        "    group_by_target=True,  # Separate by eye state (closed/open)\n",
        "    max_samples_per_group=500  # Limit for efficiency\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Created point clouds for {len(comparison_results)} datasets\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Visualize Point Clouds\n",
        "\n",
        "Compare the structure of point clouds between original and imputed datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize original dataset (closed vs open eyes)\n",
        "if 'original' in comparison_results:\n",
        "    original_pcs = comparison_results['original']\n",
        "    \n",
        "    # Filter for first channel\n",
        "    original_pcs_filtered = {\n",
        "        k: v for k, v in original_pcs.items() \n",
        "        if f'_ch{channel_idx}' in k\n",
        "    }\n",
        "    \n",
        "    if len(original_pcs_filtered) >= 2:\n",
        "        # Create comparison visualization\n",
        "        framework.visualize_comparison(\n",
        "            original_pcs_filtered,\n",
        "            titles={\n",
        "                k: k.replace('original_ch0_', '').replace('target', 'Eye ').title()\n",
        "                for k in original_pcs_filtered.keys()\n",
        "            },\n",
        "            colors={\n",
        "                k: 'blue' if 'target0' in k else 'red'\n",
        "                for k in original_pcs_filtered.keys()\n",
        "            }\n",
        "        )\n",
        "        plt.suptitle('Original Dataset - Eye Closed vs Eye Open', y=1.02)\n",
        "        plt.show()\n",
        "        print(\"✓ Original dataset visualization created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Compare Original vs Imputed Datasets\n",
        "\n",
        "Visualize how different imputation methods affect the point cloud structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare original with imputed datasets\n",
        "if len(comparison_results) > 1:\n",
        "    # Select one target group for comparison (e.g., closed eyes)\n",
        "    target_key = f'_ch{channel_idx}_target0'  # Closed eyes\n",
        "    \n",
        "    comparison_pcs = {}\n",
        "    for dataset_name, pcs in comparison_results.items():\n",
        "        key = f\"{dataset_name}{target_key}\"\n",
        "        if key in pcs:\n",
        "            # Shorten name for display\n",
        "            display_name = dataset_name.replace('_data_', '_').replace('_', ' ').title()\n",
        "            comparison_pcs[display_name] = pcs[key]\n",
        "    \n",
        "    if len(comparison_pcs) > 1:\n",
        "        framework.visualize_comparison(\n",
        "            comparison_pcs,\n",
        "            figsize=(6 * len(comparison_pcs), 5)\n",
        "        )\n",
        "        plt.suptitle('Original vs Imputed Datasets (Eye Closed)', y=1.02)\n",
        "        plt.show()\n",
        "        print(f\"✓ Compared {len(comparison_pcs)} datasets\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: PCA Projection for Easier Comparison\n",
        "\n",
        "Use PCA to project high-dimensional point clouds to 2D for easier visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA projection comparison\n",
        "if len(comparison_results) > 1:\n",
        "    target_key = f'_ch{channel_idx}_target0'  # Closed eyes\n",
        "    \n",
        "    comparison_pcs = {}\n",
        "    for dataset_name, pcs in comparison_results.items():\n",
        "        key = f\"{dataset_name}{target_key}\"\n",
        "        if key in pcs:\n",
        "            display_name = dataset_name.replace('_data_', '_').replace('_', ' ').title()\n",
        "            comparison_pcs[display_name] = pcs[key]\n",
        "    \n",
        "    if len(comparison_pcs) > 1:\n",
        "        framework.visualize_pca_projection(comparison_pcs)\n",
        "        plt.show()\n",
        "        print(\"✓ PCA projection created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Analyze Point Cloud Properties\n",
        "\n",
        "Compute statistics and distances to quantify differences between datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze point cloud properties\n",
        "target_key = f'_ch{channel_idx}_target0'  # Closed eyes\n",
        "\n",
        "print(\"Point Cloud Statistics:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for dataset_name, pcs in comparison_results.items():\n",
        "    key = f\"{dataset_name}{target_key}\"\n",
        "    if key in pcs:\n",
        "        pc = pcs[key]\n",
        "        stats = framework.analyze_point_cloud(pc, dataset_name)\n",
        "        \n",
        "        print(f\"\\n{dataset_name}:\")\n",
        "        print(f\"  Points: {stats['n_points']}\")\n",
        "        print(f\"  Mean: {stats['mean']:.4f}\")\n",
        "        print(f\"  Std: {stats['std']:.4f}\")\n",
        "        print(f\"  Range: {stats['range']:.4f}\")\n",
        "        if 'mean_pairwise_distance' in stats:\n",
        "            print(f\"  Mean pairwise distance: {stats['mean_pairwise_distance']:.4f}\")\n",
        "        print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Compute Distance Matrix\n",
        "\n",
        "Calculate distances between point clouds to quantify how different imputation methods affect the structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute distance matrix\n",
        "target_key = f'_ch{channel_idx}_target0'  # Closed eyes\n",
        "\n",
        "comparison_pcs = {}\n",
        "for dataset_name, pcs in comparison_results.items():\n",
        "    key = f\"{dataset_name}{target_key}\"\n",
        "    if key in pcs:\n",
        "        display_name = dataset_name.replace('_data_', '_').replace('_', ' ').title()\n",
        "        comparison_pcs[display_name] = pcs[key]\n",
        "\n",
        "if len(comparison_pcs) > 1:\n",
        "    distance_matrix = framework.compute_distance_matrix(comparison_pcs, metric='euclidean')\n",
        "    \n",
        "    print(\"Distance Matrix (Centroid Distance):\")\n",
        "    print(\"=\" * 80)\n",
        "    print(distance_matrix.round(4))\n",
        "    print(\"\\nLower values indicate more similar point cloud structures.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Generate Comprehensive Report\n",
        "\n",
        "Generate a detailed report comparing all datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate report\n",
        "report = framework.generate_report(\n",
        "    dataset_names=list(comparison_results.keys()),\n",
        "    channel_idx=channel_idx,\n",
        "    output_file='takens_analysis_report.txt'\n",
        ")\n",
        "\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Compare Multiple Imputation Methods\n",
        "\n",
        "Compare all imputation methods for a specific missing pattern (e.g., MCAR).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all imputation methods for MCAR pattern\n",
        "mcar_datasets = [name for name in framework.datasets.keys() \n",
        "                 if 'mcar' in name.lower() and name != 'original']\n",
        "mcar_datasets.insert(0, 'original')  # Add original at the beginning\n",
        "\n",
        "if len(mcar_datasets) > 1:\n",
        "    print(f\"Comparing MCAR imputation methods: {mcar_datasets}\")\n",
        "    \n",
        "    mcar_comparison = framework.compare_datasets(\n",
        "        dataset_names=mcar_datasets,\n",
        "        channel_idx=channel_idx,\n",
        "        group_by_target=True,\n",
        "        max_samples_per_group=500\n",
        "    )\n",
        "    \n",
        "    # Visualize for closed eyes\n",
        "    target_key = f'_ch{channel_idx}_target0'\n",
        "    mcar_pcs = {}\n",
        "    for name, pcs in mcar_comparison.items():\n",
        "        key = f\"{name}{target_key}\"\n",
        "        if key in pcs:\n",
        "            display_name = name.replace('_data_', '_').replace('_', ' ').title()\n",
        "            mcar_pcs[display_name] = pcs[key]\n",
        "    \n",
        "    if len(mcar_pcs) > 1:\n",
        "        framework.visualize_comparison(mcar_pcs, figsize=(6 * len(mcar_pcs), 5))\n",
        "        plt.suptitle('MCAR Pattern: Original vs All Imputation Methods (Eye Closed)', y=1.02)\n",
        "        plt.show()\n",
        "        \n",
        "        # Distance matrix\n",
        "        mcar_distances = framework.compute_distance_matrix(mcar_pcs)\n",
        "        print(\"\\nMCAR Imputation Methods - Distance Matrix:\")\n",
        "        print(mcar_distances.round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This framework provides:\n",
        "\n",
        "1. **Easy Dataset Loading**: Load original and imputed datasets with one function call\n",
        "2. **Automatic Point Cloud Creation**: Convert time series to point clouds automatically\n",
        "3. **Comparison Tools**: Compare multiple datasets side-by-side\n",
        "4. **Visualization**: Automatic plotting for 3D and 2D (PCA) views\n",
        "5. **Quantitative Analysis**: Statistics and distance metrics\n",
        "6. **Report Generation**: Comprehensive text reports\n",
        "\n",
        "### Key Advantages:\n",
        "\n",
        "- **Dataset-agnostic**: Works with any time series dataset\n",
        "- **Flexible**: Easy to customize parameters and comparisons\n",
        "- **Scalable**: Handles multiple datasets and imputation methods\n",
        "- **Reproducible**: Built-in random state control\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "- Experiment with different embedding dimensions and time delays\n",
        "- Compare across different missing patterns (MCAR, MAR, MNAR)\n",
        "- Analyze multiple channels simultaneously\n",
        "- Apply to other datasets (climate, traffic, etc.)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
